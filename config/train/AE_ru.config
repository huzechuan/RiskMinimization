[Task]
transfer=True
task=AE
metric=f1

[Model]
use_bert=2
model_type=SoftmaxX2
softem=False
num_decoders=3
dropout=0.5
word_embeddings=conll_
use_char=False
load_model=True
load_model_path=.transfer_data/AE/en/softmax_xlmr/en/best_model.pt,.transfer_data/AE/es/softmax_xlmr/es/best_model.pt,.transfer_data/AE/fr/softmax_xlmr/fr/best_model.pt
# ./results/ner/3/softmax_mbert/conll_03_english/best_model.pt

[Encoder]
num_layers=1
hidden_size=256

[Decoder]
num_layers=1
hidden_size=256

[Data]
data_root=./.transfer_data
embedding_root=./.data/embeddings
corpus=en_es_fr_to_ru
domain=AE
dataformat=conllu
result_root=./
sample=1.0
table=multi_logits
# table=gold_row_encoder1


[Training]
rounds=1
batch=32
epochs=5
patience=0
mu=2
anneal_method=max
L2=1e-8
lr=5e-5
top_lr=2e-3
lr_decay=0.5
# mode= train eval tune
mode=train

[Visualization]
tensor_path=ner_test
tensorboard=False

[Tune_Int]
HP_tag_dim=20
HP_rank=384,256,128,64

[Tune_Float]
