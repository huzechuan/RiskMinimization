[Task]
transfer=True
task=pos
metric=acc

[Model]
use_bert=1
model_type=SoftmaxX2
softem=True
num_decoders=5
dropout=0.5
word_embeddings=
use_char=False
load_model=True
load_model_path=.transfer_data/pos/ud_en/softmax_mbert/en/best_model.pt,.transfer_data/pos/ud_ca/softmax_mbert/ca/best_model.pt,.transfer_data/pos/ud_id/softmax_mbert/id/best_model.pt,.transfer_data/pos/ud_hi/softmax_mbert/hi/best_model.pt,.transfer_data/pos/ud_fi/softmax_mbert/fi/best_model.pt
# ./results/ner/3/softmax_mbert/conll_03_english/best_model.pt

[Encoder]
num_layers=1
hidden_size=256

[Decoder]
num_layers=1
hidden_size=256

[Data]
data_root=./.transfer_data
embedding_root=./.data/embeddings
corpus=en_ca_id_hi_fi_to_ud_ru
domain=UD
dataformat=conllu
result_root=./
sample=1.0
table=multi
# table=gold_row_encoder1


[Training]
rounds=1
batch=16
epochs=5
patience=0
mu=3
anneal_method=max
L2=1e-8
lr=5e-5
top_lr=2e-3
lr_decay=0.5
# mode= train eval tune
mode=train

[Visualization]
tensor_path=ner_test
tensorboard=False

[Tune_Int]
HP_tag_dim=20
HP_rank=384,256,128,64

[Tune_Float]
